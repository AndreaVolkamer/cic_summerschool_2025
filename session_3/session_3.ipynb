{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0828f6",
   "metadata": {},
   "source": [
    "# Session 4\n",
    "\n",
    "In this session, we will build and train a neural network for the EGFR activity prediction task using **Pytorch**. \n",
    "\n",
    "**Content:**\n",
    "1. What is Pytorch?\n",
    "2. Tensor\n",
    "3. Dataset and DataLoader\n",
    "4. Defining the Neural Network (MLP)\n",
    "5. Training\n",
    "6. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c5a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyTDC\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b40489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1afe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ab3dff",
   "metadata": {},
   "source": [
    "## What is Pytorch?\n",
    "From [Nvidia](https://www.nvidia.com/en-us/glossary/pytorch/):\n",
    "> **PyTorch** is a fully featured framework for building deep learning models, which is a type of machine learning that’s commonly used in applications like image recognition and language processing. Written in Python, it’s relatively easy for most machine learning developers to learn and use. PyTorch is distinctive for its excellent support for GPUs and its use of reverse-mode auto-differentiation, which enables computation graphs to be modified on the fly. This makes it a popular choice for fast experimentation and prototyping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0bcbbb",
   "metadata": {},
   "source": [
    "`torch.Tensor` is PyTorch's base data structure (\"data abstraction\") to represent 1D (vector), 2D (matrix) or higher dimentional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can create a vector of only zeros\n",
    "m_0 = torch.zeros(3)\n",
    "print(m_0)\n",
    "\n",
    "# or a 3 * 3 matrix of random numbers\n",
    "m_1 = torch.rand(3, 3, dtype=torch.int)\n",
    "print(m_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add393a7",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader\n",
    "[PyTorch](https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html):\n",
    "> PyTorch provides two data primitives: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset` that allow you to use pre-loaded datasets as well as your own data. `Dataset` stores the samples and their corresponding labels, and `DataLoader` wraps an iterable around the Dataset to enable easy access to the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd080052",
   "metadata": {},
   "source": [
    "As we use our own dataset, we need to create a new **Dataset** class (a class that inherits from the `Dataset` superclass). This class needs to implement the following functions:\n",
    "* `__init__`: the constructor function\n",
    "* `__len__`: number of samples in dataset\n",
    "* `__getitem__`: get a sample from the dataset at given index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b171995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=1024)\n",
    "\n",
    "def smilesToFp(smiles):\n",
    "    fpgen.GetFingerprintAsNumPy(Chem.MolFromSmiles(smiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivityDataset(Dataset):\n",
    "    def __init__(self, smiles, activity):\n",
    "        self.fingerprints = torch.tensor(list(map(smilesToFp, smiles)), dtype=torch.float)\n",
    "        self.labels = torch.tensor(activity, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fingerprint = self.fingerprints[idx]\n",
    "        label = self.labels[idx]\n",
    "        return fingerprint, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed5e420",
   "metadata": {},
   "source": [
    "Let's first load our EGFR dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffef4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "egfr_activities_df = pd.read_csv(\n",
    "    \"https://github.com/volkamerlab/cic_summerschool_2025/raw/refs/heads/main/data/EGFR-activities-prepared.csv\",\n",
    "    index_col=0,\n",
    ")\n",
    "egfr_activities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374eecc2",
   "metadata": {},
   "source": [
    "And create an `ActivityDataset` instance from the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45760ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ActivityDataset(egfr_activities_df['canonical_smiles'], egfr_activities_df['pIC50'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078cf9a0",
   "metadata": {},
   "source": [
    "We split the dataset into a training set (75%), validation set (10%), and test set (15%) using PyTorch `random_split` function: TODO @Andrea, what are good split numbers here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d54c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(0.7 * len(dataset))\n",
    "n_valid = int(0.1 * len(dataset))\n",
    "n_test = len(dataset) - n_train - n_valid\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = random_split(\n",
    "    dataset, [n_train, n_valid, n_test], generator=torch.Generator().manual_seed(42)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf3b633",
   "metadata": {},
   "source": [
    "For each split, we also create a `DataLoader` instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce6c327",
   "metadata": {},
   "source": [
    "## Defining the Neural Network (MLP)\n",
    "Here, we will build a simple **feedforward neural network** (multi-layer perceptron):\n",
    "- Input layer: 1024 (size of the fingerprint)\n",
    "- Hidden layer: 512 neurons, with ReLU activation\n",
    "- Output layer: 1 neuron (predicted pIC50 value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206ddab1",
   "metadata": {},
   "source": [
    "To build such a neural network, we need to create a subclass of PyTorch's base class `nn.Module`. In this subclass, we need to define an `__init__` function, but we also overwrite the `forward` function that defines the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f0baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivityNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActivityNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e8c951",
   "metadata": {},
   "source": [
    "## Training\n",
    "To train our MLP, we first create an instance of NN that we train `ActivityNet`. As loss function - on which the gradient is determined -, we will use the MSE. Further, we will use the optimizer `optim.Adam` for the parameter updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c976b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ActivityNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd497599",
   "metadata": {},
   "source": [
    "We train the model in *mini-batches*, which are small groups of samples defined by the `batch_size` in the DataLoader. This means that in every **training step** we update the model on all `batches` seperatly. \n",
    "\n",
    "Let's define one **training step**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # we iterate over all batches\n",
    "    for fingerprints, labels in train_dataloader:\n",
    "        \n",
    "        # zero the gradients, \n",
    "        # otherwise the new gradients will be added to the from the last iteration gardients \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward step\n",
    "        outputs = model(fingerprints)\n",
    "        \n",
    "        # empirical loss (sqeeze() to tranform a (N,1) tensor (matrix) to (N,) tensor (vector))\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        # compute the gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # updates parameters (weights & bias)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(labels)\n",
    "        \n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b42c76",
   "metadata": {},
   "source": [
    "After each training step, we test the model on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294aca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    # do not change the gradients\n",
    "    with torch.no_grad():\n",
    "        for fingerprints, labels in valid_dataloader:\n",
    "            outputs = model(fingerprints)\n",
    "            valid_loss += criterion(outputs.squeeze(), labels).item()\n",
    "    valid_loss /= len(valid_dataloader)\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7393eb",
   "metadata": {},
   "source": [
    "We are now, ready to train the NN in *epochs*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e600231",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_step(train_dataloader)\n",
    "    valid_loss = test_step(valid_dataloader)\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:03d}, Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8080509e",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1548d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for fingerprints, labels in test_dataloader:\n",
    "        outputs = model(fingerprints)\n",
    "        test_loss += criterion(outputs.squeeze(), labels).item()\n",
    "test_loss /= len(test_dataloader)\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21034e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sns.regplot(x=model(test_dataloader.dataset.fingerprints).flatten(), y=test_dataloader.dataset.labels, scatter_kws={\"s\": 10})\n",
    "plt.ylabel(\"True value\")\n",
    "plt.xlabel(\"Predicted value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e26c0",
   "metadata": {},
   "source": [
    "TODO place somewhere: Useful links:\n",
    "* python classes: https://docs.python.org/3/tutorial/classes.html\n",
    "* Dataloader & Dataset: https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "* Step by step pythorch tut:\n",
    "* Tensors tut: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7695d2e",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8245776b",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MLP that has 4 layers: input layer -> hidden layer with 256 neurons and ReLU activation -> hidden layer with  512 neurons and sigmoid activation -> output layer\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed010ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the Adams optimizer and the MSE loss function\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0130fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test this model\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: can you improve the runtime by changeing the number of neurons in the hidden layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22de4ee",
   "metadata": {},
   "source": [
    "## Challenge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_caddseminar2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
